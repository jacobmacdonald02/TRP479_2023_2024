{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QQz5rtPYKkKr"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["These lines code blocks read in all of the weather files from Sheffield. I used FTP (Filezilla) to do a bulk doanload from the CEDA Archive website. This is essentially the same script we ended up with last week"],"metadata":{"id":"Rs8FLZPnL7FY"}},{"cell_type":"code","source":["import glob\n","import pandas as pd\n","file_list = glob.glob(r\"/content/drive/MyDrive/2022-2023 Teaching/2_TRP479_Spatial_Data_Science/L7/qc-version-1/midas-open_uk-daily-temperature-obs_dv-202207_south-yorkshire_00525_sheffield_qcv-1*csv\")\n"],"metadata":{"id":"XjFKEammQRg1","executionInfo":{"status":"ok","timestamp":1713361006399,"user_tz":-60,"elapsed":685,"user":{"displayName":"Jacob Macdonald","userId":"03430160204406148918"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["#creates an empty pandas dataframe to store our yearly data\n","summary_data = pd.DataFrame([])\n","\n","# Repeat the analysis steps for each input file:\n","for fp in file_list:\n","   daily_mean=pd.DataFrame([])\n","# Read in only selected columns\n","   data = pd.read_csv(fp,\n","                    usecols=['ob_end_time', 'id_type', 'ob_hour_count',\n","       'src_id',  'max_air_temp',\n","       'min_air_temp'], skiprows=90)\n","\n","# 'drop' the last row of data in our data frame becasue we know it contains the 'end data' flag\n","   data.drop(len(data)-1,axis = 'index',inplace =True)\n","\n","# Rename the columns\n","   new_names = {\"ob_end_time\" : \"TIMESTAMP\", \"max_air_temp\" :\"MAX\", \"min_air_temp\": \"MIN\"}\n","   data = data.rename(columns=new_names)\n","\n","\n","\n","\n","\n","\n","# Slice the 'TIMESTAMP' string into DATE, YEAR, MONTH, DAY and TIME columns\n","   data[\"DATE\"] = data[\"TIMESTAMP\"].str.slice(start=0, stop=10)\n","   data[\"YEAR\"] =data[\"TIMESTAMP\"].str.slice(start=0, stop=4)\n","   data[\"MONTH\"] = data[\"TIMESTAMP\"].str.slice(start=5, stop=7)\n","   data[\"DAY\"] = data[\"TIMESTAMP\"].str.slice(start=8, stop=10)\n","   data[\"TIME\"] = data[\"TIMESTAMP\"].str.slice(start=11)\n","\n","\n","# Create empty column\n","   col_name = 'MID'\n","   data[col_name] = None\n","\n","# Calculate 'average' temperature as midpoint between max and min readings\n","   data['MID'] = (data['MAX'] + data['MIN'])/2\n","\n","   #group by month and day to get min and max values for 12 hour periods (needed for years with day and night records)\n","   grouped_month_day= data.groupby(by=['MONTH','DAY'])\n","   daily_mean['MIN']=grouped_month_day['MIN'].min() # gets MIN value for whole 24 hr period\n","   daily_mean['MAX']=grouped_month_day['MAX'].max() # gets MAX value for whole 24 hr period\n","\n","   daily_mean['MID']=grouped_month_day['MID'].mean() #mean of 'day' and 'night' MID values\n","   daily_mean['YEAR']=str(data.loc[0]['YEAR'])  #stores the YEAR\n","   daily_mean = daily_mean.reset_index()\n","   daily_mean['YEAR_MONTH'] = daily_mean['YEAR']+ \"_\" + daily_mean['MONTH']#creates YEAR_MONTH column\n","\n","\n","   monthly_mean= daily_mean.groupby('YEAR_MONTH').mean().reset_index()     #dataframe with monthly avverages\n","   summary_data=pd.concat([summary_data, monthly_mean], ignore_index=True) #pd.append() has been superseded by pd.concat()\n"],"metadata":{"id":"T-SFI-C-QObH","executionInfo":{"status":"ok","timestamp":1713361020528,"user_tz":-60,"elapsed":261,"user":{"displayName":"Jacob Macdonald","userId":"03430160204406148918"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7QOxJm0aKuJj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1ywOfdE9YO2f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#fp = r'/content/drive/Shareddrives/TRP479_Spatial_Data_Science_Data/L7/sy_summary_data.csv'\n","summary_data.head(10)\n","summary_data.tail(10)\n","#summary_data.to_csv(fp)"],"metadata":{"id":"gcWVjv1iFR5S"},"execution_count":null,"outputs":[]}]}